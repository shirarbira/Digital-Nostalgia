<!doctype html>
<html>
<head>
<!--link rel="stylesheet" href="css-style-sheets/theorymaking.css" -->
<link rel="stylesheet" href="newstyle.css">
<meta charset="UTF-8">
<title></title>
</head>
<div id="paper"> 
<header> <a href="index.html"><img id="header" src="images/digital-nostalgia-header.jpg"></a></header>
<div>
<section class="content_float" style="font-size: 15px;">
<a href="http://composingdigitalmedia.org/dmtp/webs/shif/html-code/assigments.html">return to assigments page </a>
<h1> Evil Media Presentation Paper </h1>
<p>Reading “Evil Media”, specifically the chapter, “Togetherness”, words and phrases such as “social engineering” (47), “instructions” (49), “cyborg” (54), and “algorithmicization of romantic behaviors” (64) directed the rhetoric. And this makes sense—for the purpose of the book is to expose the hidden, recessive, and opaque evils inherent in media systems, techniques, and practices of mediation. Yet, in reading “Togetherness”, an exploration of the intersection between the human mind/behavior and technology/infrastructure, I came to realize that the manifestations of these intersections are conceptualized as innovative, progressive, and advantageous software and applications. The question thus arises why do we not perceive such applications as evil in the first place, why do we instead praise the technology and label it as positive advancements, why is it that cyborgs are diabolical yet Siri is an intelligent personal assistant? And finally how is that these products are marketed in such a way that their manipulative and evil features are completely concealed, and in exchange, marketed as something favorable?</p><br>
<p>One of the main concerns of the book is the algorithmicization of the human. Of online dating, the authors write, “The crucial aspect here is to lift actions out of the ensemble of behaviors from a wider set of relations and to filter them in relation to a set of prepared and preferentially ordered triggers. This process of detachment allows bodily operations and linguistic behaviors to be interpreted and handled by the same sets of tools: to be treated as media” (Fuller and Goffey 64). This process of anthropomorphizing technology/ systemizing behavior (there’s certainly a rhetorical difference between the two, whether the action is being done to technology or humans) pervades most of our interactions with media. Yet, our response to such anthropomorphized technology varies drastically. A LifeHacker online article describes Facebook’s adverting program: “It boils down to this: the more information you put about yourself on Facebook—where you live, your age, where (and if) you graduated college, the companies, brands, and activities you like, and even where you work—determines what kind of ads you'll see” (Klosowski). Essentially the same process occurs with Google’s ad program, which uses browser history to determine the advertising. However, when the shoes you just looked at on Zappos shows up while you’re looking up a word on dictionary.com, the usual response is something along the lines of, “How does the advertisement know!” or “Wow, this is super invasive”, or “Go away shoes, I just closed your tab so I could do my homework”. There seems to be generally negative and skeptical connotation to the idea of personalized advertising.</p><br>
<p>        	This suspicion however, disappears when Tinder finds someone a match. Using Facebook profiles, user’s “basic” information, interests, and geographic location, the app introduces two users, opening a chat. In the same way AdSense works, Tinder turns behavior into media and software. The same data-mining tools are used to “understand how people think and to see where that intersects with technology” (Fuller and Goffey 47). Why is it then, that personalized advertising is unnerving, evoking the eerie feeling of being watched, while Tinder won best new startup of 2013 (TechCrunch)?</p><br>
<p>Perhaps it is an issue of consent. Tinder users deliberately enter their interests and information in hopes of being matched up, whereas Internet users do not ask advertising programs to use their information explicitly. Yet, this argument becomes invalid when the users realize not only have they already given consent to the websites to track the browser history through default privacy settings, but also, that they input their favorite movies, stores, and interests on their Facebook profiles. Is there a difference between the two technologies? This raises a multiplicity of further questions such as: why is that people feel the need to share their interests on Facebook? How does privacy settings get away with what they do without the general majority of people being aware of what is happening? Perhaps the most important question is which is more evil: people intentionally turning their behaviors into algorithms and codes with apps like Tinder, or applications like AdSense, which underhandedly benefit from people’s codified interests and behaviors?
</p><br>
<p>Tinder’s mantra is “It’s like real life, but better.”  This motto possibly best encompasses the purpose of “Evil Media.” Tinder’s motto demonstrates the underlying evils inherent in our media systems—that the manipulative features are concealed and opaque, and instead, conceived as something innovative and helpful. That users purposefully cannot see the evil attributes at work, and thus instead, see the media technologies as better than real life. “Evil Media” proposes a cultivation of knowledge; a knowledge of “how to manipulate such objects or processes (which knowing yourself to be manipulated or manipulable in turn) as well as the effects or consequences that the trickery or cunning of such manipulation produces” (Fuller and Goffey 6). Attaining this knowledge is becoming increasingly difficult when applications brand themselves as being better than real life. There is no solution to put forth here. Instead, the challenge re-arises: how to expose the fundamental similarities between unnerving technologies like personalized ads and seemingly creative applications like Tinder? While cultivating this knowledge is becoming increasingly difficult, it is at the same time, becoming increasingly necessary.</p><br>
<p>Sources Cited:<br>
Fuller, Matthew, and Andrew Goffey. Evil Media. Cambridge, MA: MIT, 2012. Print.<br> 
Klosowski, Thorin. "How Facebook Uses Your Data to Target Ads, Even Offline." Lifehacker. N.p., 11 Mar. 2013. Web. 24 Apr. 2014.<br>
 
"Tinder Wins Best New Startup of 2013 | Crunchies Awards 2013 | TechCrunch." TechCrunch. TechCrunch, n.d. Web. 25 Apr. 2014.</p>




   
</section>



<div id="navigation">
  <a href="index.html"><img id="nav" src="home.nav.jpg" width="126" height="142"></a><br>
<a href="theory-making.html"><img id="nav" src="project.nav.jpg"width="126" height="142"></a><br>
<a href="/html-code/video.html"><img id="nav" src="experience.nav.jpg"width="126" height="142"></a><br>
<a href="/html-code/gallery.html"><img id="nav" src="gallery.nav.jpg"width="126" height="142"></a><br>
<a href="http://composingdigitalmedia.org/dmtp/webs/shif/html-code/assigments.html"><img id="nav" src="info.nav.jpg"width="126" height="142"></a><br></div>
</div></div>
</body>
</html>
